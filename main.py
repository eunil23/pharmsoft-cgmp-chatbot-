import streamlit as st
from langchain_core.messages.chat import ChatMessage
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_anthropic import ChatAnthropic
from langchain import hub
from langchain.chains import RetrievalQAWithSourcesChain
from langchain_core.prompts import PromptTemplate
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
import tempfile
import os
import hashlib
import fitz  # PyMuPDF
import pandas as pd
from io import StringIO

# í™˜ê²½ë³€ìˆ˜ ì„¤ì • ë° API í‚¤ ê´€ë¦¬
def load_config():
    """í™˜ê²½ë³„ í˜¸í™˜ì„±ì„ ê³ ë ¤í•œ ì„¤ì • ë¡œë”©"""
    
    # ë¡œì»¬ ê°œë°œ í™˜ê²½ì—ì„œëŠ” .env íŒŒì¼ ë¡œë“œ ì‹œë„
    try:
        load_dotenv()
    except:
        pass  # ë°°í¬ í™˜ê²½ì—ì„œëŠ” dotenvê°€ ì—†ì„ ìˆ˜ ìˆìŒ
    
    config = {}
    
    # OpenAI API Key
    config['openai_key'] = (
        st.secrets.get("api_keys", {}).get("openai") or  # secrets.toml ì„¹ì…˜ ë°©ì‹
        st.secrets.get("OPENAI_API_KEY") or              # secrets.toml ë£¨íŠ¸ ë°©ì‹
        os.getenv("OPENAI_API_KEY")                      # í™˜ê²½ë³€ìˆ˜
    )
    
    # Anthropic API Key
    config['anthropic_key'] = (
        st.secrets.get("api_keys", {}).get("anthropic") or
        st.secrets.get("ANTHROPIC_API_KEY") or
        os.getenv("ANTHROPIC_API_KEY")
    )
    
    # LangSmith ì„¤ì • (ì„ íƒì‚¬í•­)
    config['langsmith_key'] = (
        st.secrets.get("langsmith", {}).get("api_key") or
        st.secrets.get("LANGSMITH_API_KEY") or
        os.getenv("LANGSMITH_API_KEY")
    )
    
    config['langsmith_project'] = (
        st.secrets.get("langsmith", {}).get("project") or
        st.secrets.get("LANGSMITH_PROJECT") or
        os.getenv("LANGSMITH_PROJECT")
    )
    
    return config

def check_api_keys():
    """API í‚¤ ì„¤ì • ìƒíƒœ í™•ì¸"""
    config = load_config()
    
    missing_keys = []
    
    if not config['openai_key']:
        missing_keys.append("OpenAI API Key")
    
    if not config['anthropic_key']:
        missing_keys.append("Anthropic API Key")
    
    if missing_keys:
        st.error(f"âš ï¸ ë‹¤ìŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {', '.join(missing_keys)}")
        st.info("ğŸ’¡ secrets.toml íŒŒì¼ì´ë‚˜ í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        with st.expander("ğŸ”§ ì„¤ì • ë°©ë²•"):
            st.code("""
# .streamlit/secrets.toml íŒŒì¼ ìƒì„±:
[api_keys]
openai = "your-openai-key"
anthropic = "your-anthropic-key"
""", language="toml")
        return False
    
    return True

# ì „ì—­ ì„¤ì • ë¡œë“œ
APP_CONFIG = load_config()

st.set_page_config(page_title="ê·œì • ì±—ë´‡")
st.title("íŒœì†Œí”„íŠ¸ cGMP ê·œì • ì±—ë´‡")
st.caption("cGMP ê·œì •ì— ëŒ€í•´ì„œ ìì„¸íˆ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.")

# API í‚¤ í™•ì¸ - ì•± ì‹œì‘ ì‹œ ì²´í¬
if not check_api_keys():
    st.stop()  # API í‚¤ê°€ ì—†ìœ¼ë©´ ì•± ì‹¤í–‰ ì¤‘ë‹¨

# ì²˜ìŒ 1ë²ˆë§Œ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì½”ë“œ
if "messages" not in st.session_state:
    # ëŒ€í™”ê¸°ë¡ì„ ì €ì¥í•˜ê¸° ìœ„í•œ ìš©ë„ë¡œ ìƒì„±í•œë‹¤.
    st.session_state["messages"] = []

# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”ë¥¼ ì„¸ì…˜ ìƒíƒœë¡œ ê´€ë¦¬
@st.cache_resource
def initialize_database():
    """ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜ (ìºì‹œëœ ë¦¬ì†ŒìŠ¤ë¡œ ê´€ë¦¬)"""
    try:
        # OpenAIì—ì„œ ì œê³µí•˜ëŠ” Embedding Modelì„ í™œìš©í•´ì„œ `chunk`ë¥¼ vectorí™”
        embedding = OpenAIEmbeddings(
            model="text-embedding-3-large",
            openai_api_key=APP_CONFIG['openai_key']  # API í‚¤ ëª…ì‹œì  ì „ë‹¬
        )
        
        # ë°°í¬ í™˜ê²½ì„ ê³ ë ¤í•œ ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        if os.path.exists("./chroma"):
            persist_directory = "./chroma"
        else:
            # ë°°í¬í™˜ê²½ìš© - ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚¬ìš©
            persist_directory = tempfile.mkdtemp(prefix="chroma_")
            st.info(f"ì„ì‹œ ì €ì¥ì†Œ ì‚¬ìš©: {persist_directory}")
        
        # ë°ì´í„°ë¥¼ ì €ì¥í•  ë•Œ 
        database = Chroma(
            collection_name="chroma-cGMP",
            persist_directory=persist_directory,
            embedding_function=embedding,
        )
        return database
    except Exception as e:
        st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        return None

# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
if "database" not in st.session_state or st.session_state["database"] is None:
    st.session_state["database"] = initialize_database()

# ì‚¬ì´ë“œë°” ìƒì„±
with st.sidebar:
    st.header("ğŸ“š ë¬¸ì„œ ê´€ë¦¬")
    
    # API í‚¤ ìƒíƒœ í‘œì‹œ
    with st.expander("ğŸ”‘ API ì„¤ì • ìƒíƒœ"):
        if APP_CONFIG['openai_key']:
            st.success("âœ… OpenAI API Key ì„¤ì •ë¨")
        else:
            st.error("âŒ OpenAI API Key ì—†ìŒ")
            
        if APP_CONFIG['anthropic_key']:
            st.success("âœ… Anthropic API Key ì„¤ì •ë¨")
        else:
            st.error("âŒ Anthropic API Key ì—†ìŒ")
            
        if APP_CONFIG['langsmith_key']:
            st.info(f"ğŸ“Š LangSmith í”„ë¡œì íŠ¸: {APP_CONFIG['langsmith_project']}")
    
    # ì €ì¥ëœ ë¬¸ì„œ ëª©ë¡ í‘œì‹œ
    if "processed_files" not in st.session_state:
        st.session_state["processed_files"] = set()
    
    if st.session_state["processed_files"]:
        st.subheader("ğŸ’¾ ì €ì¥ëœ ë¬¸ì„œ")
        for filename in st.session_state["processed_files"]:
            st.write(f"âœ… {filename}")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸ ë²„íŠ¼
        if st.button("ğŸ” DB ìƒíƒœ í™•ì¸"):
            try:
                if st.session_state["database"]:
                    total_docs = st.session_state["database"].get()
                    st.info(f"ì´ ì €ì¥ëœ ì²­í¬: {len(total_docs['documents'])}ê°œ")
                    
                    # íŒŒì¼ë³„ ì²­í¬ ìˆ˜ í‘œì‹œ
                    file_counts = {}
                    for metadata in total_docs['metadatas']:
                        if metadata and 'source' in metadata:
                            filename = metadata['source']
                            file_counts[filename] = file_counts.get(filename, 0) + 1
                    
                    st.write("ğŸ“Š íŒŒì¼ë³„ ì²­í¬ ìˆ˜:")
                    for filename, count in file_counts.items():
                        st.write(f"  â€¢ {filename}: {count}ê°œ")
                        
                else:
                    st.error("ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    
            except Exception as e:
                st.error(f"DB ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)}")
    else:
        st.info("ì•„ì§ ì—…ë¡œë“œëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    st.divider()
    
    # ì´ˆê¸°í™” ë²„íŠ¼ ìƒì„±
    clear_btn = st.button("ğŸ’¬ ëŒ€í™” ì´ˆê¸°í™”")
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ—‘ï¸ ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”", type="secondary"):
        try:
            # ë°©ë²• 1: ì„¸ì…˜ ìƒíƒœì—ì„œ ë°ì´í„°ë² ì´ìŠ¤ ì œê±°
            if "database" in st.session_state:
                del st.session_state["database"]
            
            # ë°©ë²• 2: ìºì‹œëœ ë¦¬ì†ŒìŠ¤ í´ë¦¬ì–´
            initialize_database.clear()
            
            # ë°©ë²• 3: ë¬¼ë¦¬ì  íŒŒì¼ ì‚­ì œ (ë¡œì»¬ í™˜ê²½ì¸ ê²½ìš°)
            import shutil
            if os.path.exists("./chroma"):
                shutil.rmtree("./chroma")
            
            # ì²˜ë¦¬ëœ íŒŒì¼ ëª©ë¡ ì´ˆê¸°í™”
            st.session_state["processed_files"] = set()
            st.session_state["messages"] = []
            
            st.success("ë°ì´í„°ë² ì´ìŠ¤ê°€ ì™„ì „íˆ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.info("í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ê±°ë‚˜ ìƒˆ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            
        except Exception as e:
            st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ì„¸ì…˜ ìƒíƒœëŠ” ì´ˆê¸°í™”
            if "database" in st.session_state:
                del st.session_state["database"]
            st.session_state["processed_files"] = set()
            st.session_state["messages"] = []
            st.info("ì„¸ì…˜ ìƒíƒœëŠ” ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•´ì£¼ì„¸ìš”.")

def get_file_hash(file_content):
    """íŒŒì¼ ë‚´ìš©ì˜ í•´ì‹œê°’ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    return hashlib.md5(file_content).hexdigest()

def is_file_already_processed(filename, file_hash):
    """íŒŒì¼ì´ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    try:
        if not st.session_state.get("database"):
            return False
            
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í•´ë‹¹ íŒŒì¼ì˜ ë¬¸ì„œë“¤ì„ ê²€ìƒ‰
        existing_docs = st.session_state["database"].get(
            where={"source": filename}
        )
        
        # ê°™ì€ íŒŒì¼ëª…ê³¼ í•´ì‹œê°’ì„ ê°€ì§„ ë¬¸ì„œê°€ ìˆëŠ”ì§€ í™•ì¸
        if existing_docs['documents']:
            for metadata in existing_docs['metadatas']:
                if metadata and metadata.get('file_hash') == file_hash:
                    return True
        return False
    except Exception as e:
        st.warning(f"ì¤‘ë³µ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return False

def extract_pdf_content_advanced(file_path):
    """PyMuPDFë¥¼ ì‚¬ìš©í•´ì„œ PDFì—ì„œ í…ìŠ¤íŠ¸, í‘œ, êµ¬ì¡° ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    doc = fitz.open(file_path)
    documents = []
    
    for page_num in range(len(doc)):
        page = doc[page_num]
        
        # ê¸°ë³¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text = page.get_text()
        
        # í‘œ ì¶”ì¶œ ì‹œë„
        tables = page.find_tables()
        table_content = ""
        
        if tables:
            for table_num, table in enumerate(tables):
                try:
                    # í‘œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ê³  ë¬¸ìì—´ë¡œ ë³€í™˜
                    table_data = table.extract()
                    if table_data:
                        # í‘œë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                        table_text = f"\n\n[í‘œ {table_num + 1}]\n"
                        for row in table_data:
                            # None ê°’ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ë³€í™˜
                            clean_row = [str(cell) if cell is not None else "" for cell in row]
                            table_text += "| " + " | ".join(clean_row) + " |\n"
                        table_content += table_text
                except Exception as e:
                    st.warning(f"í‘œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ (í˜ì´ì§€ {page_num + 1}): {str(e)}")
        
        # ì´ë¯¸ì§€ ì •ë³´ ì¶”ì¶œ
        image_list = page.get_images()
        image_content = ""
        if image_list:
            image_content = f"\n\n[ì´ í˜ì´ì§€ì—ëŠ” {len(image_list)}ê°œì˜ ì´ë¯¸ì§€ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤]\n"
        
        # í…ìŠ¤íŠ¸ ë¸”ë¡ ì •ë³´ (ì„œì‹, ìœ„ì¹˜ ë“±)
        blocks = page.get_text("dict")
        structured_text = ""
        
        for block in blocks["blocks"]:
            if "lines" in block:
                for line in block["lines"]:
                    for span in line["spans"]:
                        # í°íŠ¸ í¬ê¸°ì™€ ìŠ¤íƒ€ì¼ ì •ë³´ í¬í•¨
                        font_size = span.get("size", 12)
                        font_flags = span.get("flags", 0)
                        text_content = span.get("text", "")
                        
                        # ì œëª©ì´ë‚˜ ì¤‘ìš”í•œ í…ìŠ¤íŠ¸ ì‹ë³„ (í° í°íŠ¸ë‚˜ ë³¼ë“œ)
                        if font_size > 14 or font_flags & 2**4:  # ë³¼ë“œ ì²´í¬
                            structured_text += f"\n### {text_content}\n"
                        else:
                            structured_text += text_content
        
        # ëª¨ë“  ë‚´ìš© ê²°í•©
        combined_content = f"""
í˜ì´ì§€ {page_num + 1} ë‚´ìš©:

{text}

{table_content}

{image_content}

êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸:
{structured_text}
        """.strip()
        
        # Document ê°ì²´ ìƒì„±
        doc_obj = Document(
            page_content=combined_content,
            metadata={
                "page": page_num + 1,
                "has_tables": len(tables) > 0,
                "table_count": len(tables),
                "image_count": len(image_list),
                "total_pages": len(doc)
            }
        )
        documents.append(doc_obj)
    
    doc.close()
    return documents

def process_pdf_file(uploaded_file):
    """PDF íŒŒì¼ì„ ì²˜ë¦¬í•˜ê³  Chroma DBì— ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        # ë°ì´í„°ë² ì´ìŠ¤ í™•ì¸
        if not st.session_state.get("database"):
            return f"âŒ '{uploaded_file.name}': ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        # íŒŒì¼ ë‚´ìš© ì½ê¸°
        file_content = uploaded_file.read()
        file_hash = get_file_hash(file_content)
        
        # ì¤‘ë³µ ì²´í¬
        if is_file_already_processed(uploaded_file.name, file_hash):
            return f"âš ï¸ '{uploaded_file.name}'ì€ ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ì…ë‹ˆë‹¤."
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
            tmp_file.write(file_content)
            tmp_file_path = tmp_file.name
        
        try:
            # ê³ ê¸‰ PDF ì¶”ì¶œ ì‹œë„
            try:
                documents = extract_pdf_content_advanced(tmp_file_path)
                extraction_method = "ê³ ê¸‰ ì¶”ì¶œ (í‘œ, ì´ë¯¸ì§€, êµ¬ì¡° í¬í•¨)"
            except Exception as e:
                # ê¸°ë³¸ PDF ë¡œë”ë¡œ í´ë°±
                loader = PyPDFLoader(tmp_file_path)
                documents = loader.load()
                extraction_method = "ê¸°ë³¸ ì¶”ì¶œ"
            
            if not documents:
                return f"âŒ '{uploaded_file.name}': PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            # í…ìŠ¤íŠ¸ ë¶„í•  (ë” í° ì²­í¬ í¬ê¸°ë¡œ í‘œì™€ êµ¬ì¡° ë³´ì¡´)
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=1500,  # í‘œì™€ êµ¬ì¡°ë¥¼ ë³´ì¡´í•˜ê¸° ìœ„í•´ ë” í° ì²­í¬
                chunk_overlap=300,
                length_function=len,
                separators=["\n\n", "\n", ". ", " ", ""]
            )
            splits = text_splitter.split_documents(documents)
            
            # ë©”íƒ€ë°ì´í„°ì— íŒŒì¼ ì •ë³´ ì¶”ê°€
            for i, split in enumerate(splits):
                original_metadata = split.metadata.copy()
                split.metadata = {
                    'source': uploaded_file.name,
                    'file_hash': file_hash,
                    'upload_time': str(st.session_state.get('current_time', '')),
                    'page': original_metadata.get('page', 1),
                    'chunk_id': f"{uploaded_file.name}_chunk_{i+1}",
                    'has_tables': original_metadata.get('has_tables', False),
                    'table_count': original_metadata.get('table_count', 0),
                    'image_count': original_metadata.get('image_count', 0),
                    'extraction_method': extraction_method
                }
            
            # Chroma DBì— ì¶”ê°€
            st.session_state["database"].add_documents(splits)
            
            # ì²˜ë¦¬ëœ íŒŒì¼ ëª©ë¡ì— ì¶”ê°€
            st.session_state["processed_files"].add(uploaded_file.name)
            
            # ìƒì„¸ ì •ë³´ í¬í•¨í•œ ì„±ê³µ ë©”ì‹œì§€
            table_info = ""
            image_info = ""
            total_tables = sum(doc.metadata.get('table_count', 0) for doc in documents)
            total_images = sum(doc.metadata.get('image_count', 0) for doc in documents)
            
            if total_tables > 0:
                table_info = f", í‘œ {total_tables}ê°œ"
            if total_images > 0:
                image_info = f", ì´ë¯¸ì§€ {total_images}ê°œ"
            
            return f"âœ… '{uploaded_file.name}': {len(splits)}ê°œ ì²­í¬ë¡œ ì²˜ë¦¬ ì™„ë£Œ ({extraction_method}{table_info}{image_info})"
            
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            os.unlink(tmp_file_path)
            
    except Exception as e:
        return f"âŒ '{uploaded_file.name}': ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ - {str(e)}"

# ì´ì „ ëŒ€í™”ë¥¼ ì¶œë ¥
def print_messages():
    for chat_message in st.session_state["messages"]:
        st.chat_message(chat_message.role).write(chat_message.content)

# ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì¶”ê°€
def add_message(role, message):
    st.session_state["messages"].append(ChatMessage(role=role, content=message))

def get_ai_message(user_input):
    # ë°ì´í„°ë² ì´ìŠ¤ í™•ì¸
    if "database" not in st.session_state or st.session_state["database"] is None:
        return {
            "answer": "ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ê±°ë‚˜ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.",
            "sources": []
        }
    
    # Claude ëª¨ë¸ ì´ˆê¸°í™” (API í‚¤ ëª…ì‹œì  ì „ë‹¬)
    llm = ChatAnthropic(
        model="claude-sonnet-4-20250514",
        anthropic_api_key=APP_CONFIG['anthropic_key']
    )
    
    try:
        # ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ ê°€ì ¸ì˜¤ê¸° (ë” ë§ì€ ë¬¸ì„œ ê²€ìƒ‰)
        retriever = st.session_state["database"].as_retriever(
            search_type="similarity",
            search_kwargs={"k": 5}  # 5ê°œ ë¬¸ì„œë¡œ ì¦ê°€
        )
        docs = retriever.get_relevant_documents(user_input)
    except Exception as e:
        return {
            "answer": f"ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\n\në°ì´í„°ë² ì´ìŠ¤ë¥¼ ì´ˆê¸°í™”í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            "sources": []
        }
    
    if not docs:
        return {
            "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ì—…ë¡œë“œëœ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¬¸ì„œê°€ ì˜¬ë°”ë¥´ê²Œ ì—…ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.",
            "sources": []
        }
    
    # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    context = "\n\n".join([f"[ë¬¸ì„œ: {doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')}]\n{doc.page_content}" for doc in docs])
    
    # ì¶œì²˜ ì •ë³´ ìˆ˜ì§‘ (ì¤‘ë³µ ì œê±° ë° ì •ë¦¬)
    sources = []
    for doc in docs:
        if hasattr(doc, 'metadata') and doc.metadata:
            source_name = doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ëŠ” ì¶œì²˜')
            page_num = doc.metadata.get('page', '')
            
            # ì¶œì²˜ ì •ë³´ í¬ë§·íŒ…
            if page_num and str(page_num).isdigit():
                source_info = f"{source_name} (í˜ì´ì§€ {page_num})"
            else:
                source_info = source_name
            
            if source_info not in sources:  # ì¤‘ë³µ ì œê±°
                sources.append(source_info)
    
    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
    prompt_template = """
    ë‹¹ì‹ ì€ cGMP ê·œì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë¬¸ì„œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ìƒì„¸í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

    ë¬¸ì„œ ë‚´ìš©:
    {context}

    ì§ˆë¬¸: {question}

    ë‹µë³€ ì‹œ ë‹¤ìŒ ì‚¬í•­ì„ ì¤€ìˆ˜í•´ì£¼ì„¸ìš”:
    1. ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
    2. êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì •ë³´ë¥¼ í¬í•¨í•˜ì„¸ìš”
    3. ë‹¨ê³„ë³„ ì ˆì°¨ê°€ ìˆë‹¤ë©´ ìˆœì„œëŒ€ë¡œ ì„¤ëª…í•˜ì„¸ìš”
    4. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”

    ë‹µë³€:
    """
    
    prompt = PromptTemplate(
        template=prompt_template,
        input_variables=["context", "question"]
    )
    
    # LLMì— ì§ˆë¬¸
    formatted_prompt = prompt.format(context=context, question=user_input)
    response = llm.invoke(formatted_prompt)
    
    # ì‘ë‹µê³¼ ì¶œì²˜ ì •ë³´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜
    return {
        "answer": response.content if hasattr(response, 'content') else str(response),
        "sources": sources
    }

# ì´ˆê¸°í™” ë²„íŠ¼ì´ ëˆŒë¦¬ë©´...
if clear_btn:
    st.session_state["messages"] = []

# ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
print_messages()

# íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ (ì±— ì…ë ¥ ìœ„ì—)
st.subheader("ğŸ“ ë¬¸ì„œ ì—…ë¡œë“œ")
col1, col2 = st.columns([3, 1])

with col1:
    uploaded_files = st.file_uploader(
        "PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì„œ ì±—ë´‡ì— í•™ìŠµì‹œí‚¤ì„¸ìš”",
        type=['pdf'],
        accept_multiple_files=True,
        help="ì—¬ëŸ¬ PDF íŒŒì¼ì„ ë™ì‹œì— ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        key="main_uploader"
    )

with col2:
    if uploaded_files:
        process_btn = st.button("ğŸ“¥ ë¬¸ì„œ ì²˜ë¦¬í•˜ê¸°", type="primary", key="main_process")

# íŒŒì¼ ì²˜ë¦¬ ë¡œì§
if uploaded_files and 'process_btn' in locals() and process_btn:
    import datetime
    st.session_state['current_time'] = str(datetime.datetime.now())
    
    with st.spinner("ğŸ“„ PDF íŒŒì¼ë“¤ì„ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        results = []
        for uploaded_file in uploaded_files:
            result = process_pdf_file(uploaded_file)
            results.append(result)
        
        # ê²°ê³¼ í‘œì‹œ
        for result in results:
            if result.startswith("âœ…"):
                st.success(result)
            elif result.startswith("âš ï¸"):
                st.warning(result)
            else:
                st.error(result)
        
        # ì²˜ë¦¬ ì™„ë£Œ ë©”ì‹œì§€ (ì• ë‹ˆë©”ì´ì…˜ ì œê±°)
        st.info("ğŸ“„ ë¬¸ì„œ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

st.divider()

# ì‚¬ìš©ìì˜ ì…ë ¥
user_input = st.chat_input("cGMP ê·œì • ê´€ë ¨í•˜ì—¬ ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë§ì”€í•´ ì£¼ì„¸ìš”.")

# ë§Œì•½ì— ì‚¬ìš©ì ì…ë ¥ì´ ë“¤ì–´ì˜¤ë©´...
if user_input:
    # ì‚¬ìš©ìì˜ ì…ë ¥
    st.chat_message("user").write(user_input)

    # AI ì‘ë‹µ
    with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        try:
            ai_response = get_ai_message(user_input)
            
            # ë‹µë³€ê³¼ ì¶œì²˜ ë¶„ë¦¬
            if isinstance(ai_response, dict):
                answer = ai_response.get("answer", "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                sources = ai_response.get("sources", [])
                
                # AI ë‹µë³€ í‘œì‹œ
                st.chat_message("ai").write(answer)
                
                # ì¶œì²˜ ì •ë³´ í‘œì‹œ
                if sources:
                    with st.expander("ğŸ“š ì°¸ê³  ì¶œì²˜"):
                        for i, source in enumerate(sources, 1):
                            st.write(f"{i}. {source}")
                
                # ëŒ€í™”ê¸°ë¡ì—ëŠ” ë‹µë³€ë§Œ ì €ì¥
                display_message = answer
                if sources:
                    display_message += f"\n\n**ì°¸ê³  ì¶œì²˜:**\n" + "\n".join([f"- {source}" for source in sources])
                
            else:
                # ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ í˜•íƒœì¸ ê²½ìš°
                display_message = str(ai_response)
                st.chat_message("ai").write(display_message)
            
            # ëŒ€í™”ê¸°ë¡ì„ ì €ì¥í•œë‹¤.
            add_message("user", user_input)
            add_message("ai", display_message)
            
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.info("API í‚¤ ì„¤ì •ê³¼ Chroma ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")